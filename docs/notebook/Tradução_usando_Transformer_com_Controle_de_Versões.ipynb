{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ponderada: Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "F3HpfjXRkvru"
      },
      "outputs": [],
      "source": [
        "#importações\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVTOG1Zskzr7"
      },
      "outputs": [],
      "source": [
        "# Carregar dataset TED Talk ->EN)\n",
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)\n",
        "train_examples, val_examples = examples['train'], examples['validation']\n",
        "\n",
        "# Subamostragem para treino \n",
        "train_examples = train_examples.take(2000)\n",
        "val_examples = val_examples.take(500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "BjN9YZiilHcR"
      },
      "outputs": [],
      "source": [
        "# Tokenizador oficial\n",
        "model_name = \"ted_hrlr_translate_pt_en_converter\"\n",
        "tf.keras.utils.get_file(\n",
        "    f\"{model_name}.zip\",\n",
        "    f\"https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip\",\n",
        "    cache_dir='.', cache_subdir='', extract=True\n",
        ")\n",
        "tokenizers = tf.saved_model.load(\n",
        "    \"./ted_hrlr_translate_pt_en_converter_extracted/ted_hrlr_translate_pt_en_converter\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "7lRt1G5HlY5J"
      },
      "outputs": [],
      "source": [
        "# Preparar batches\n",
        "MAX_TOKENS = 128\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def encode_and_tensorize(pt, en):\n",
        "    \"\"\"\n",
        "    Tokeniza, corta e prepara tensores para treino de modelo Transformer.\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    pt : tf.Tensor ou str\n",
        "        Frases em português a serem tokenizadas.\n",
        "    en : tf.Tensor ou str\n",
        "        Frases correspondentes em inglês a serem tokenizadas.\n",
        "\n",
        "    Retorno:\n",
        "    --------\n",
        "    tuple:\n",
        "        - inputs: tupla contendo:\n",
        "            - pt: tensor das frases em português tokenizadas e truncadas.\n",
        "            - decoder_input: tensor das frases em inglês tokenizadas, truncadas e deslocadas para entrada do decodificador.\n",
        "        - decoder_target: tensor das frases em inglês tokenizadas e truncadas, deslocadas para servir como alvo do decodificador.\n",
        "\n",
        "    Observações:\n",
        "    ------------\n",
        "    - O comprimento máximo de tokens do português é definido por MAX_TOKENS.\n",
        "    - O comprimento máximo de tokens do inglês é MAX_TOKENS + 1, devido ao deslocamento do decoder.\n",
        "    \"\"\"\n",
        "    pt = tokenizers.pt.tokenize(pt)[:, :MAX_TOKENS].to_tensor()\n",
        "    en = tokenizers.en.tokenize(en)[:, :MAX_TOKENS+1].to_tensor()\n",
        "    decoder_input = en[:, :-1]\n",
        "    decoder_target = en[:, 1:]\n",
        "    return (pt, decoder_input), decoder_target\n",
        "\n",
        "\n",
        "train_batches_for_fit = (train_examples\n",
        "                         .shuffle(1024)\n",
        "                         .batch(BATCH_SIZE)\n",
        "                         .map(encode_and_tensorize, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                         .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "val_batches_for_fit = (val_examples\n",
        "                       .batch(BATCH_SIZE)\n",
        "                       .map(encode_and_tensorize, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                       .prefetch(tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "qcOZFT_Pw7x0"
      },
      "outputs": [],
      "source": [
        "# definir camadas transformer\n",
        "def positional_encoding(length, depth):\n",
        "    \"\"\"\n",
        "    Gera codificação posicional usando funções seno e cosseno.\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    length : int\n",
        "        Comprimento máximo das sequências.\n",
        "    depth : int\n",
        "        Dimensão do embedding (d_model).\n",
        "\n",
        "    Retorno:\n",
        "    --------\n",
        "    tf.Tensor\n",
        "        Tensor de codificação posicional de forma (length, depth), do tipo float32.\n",
        "    \"\"\"\n",
        "    depth = depth/2\n",
        "    positions = np.arange(length)[:, np.newaxis]\n",
        "    depths = np.arange(depth)[np.newaxis, :]/depth\n",
        "    angle_rates = 1 / (10000**depths)\n",
        "    angle_rads = positions * angle_rates\n",
        "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Camada de embedding que combina embedding de tokens com codificação posicional.\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    vocab_size : int\n",
        "        Tamanho do vocabulário.\n",
        "    d_model : int\n",
        "        Dimensão do embedding.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "        self.pos_encoding = positional_encoding(2048, d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"\n",
        "        Aplica embedding e adiciona codificação posicional.\n",
        "\n",
        "        Parâmetros:\n",
        "        -----------\n",
        "        x : tf.Tensor ou tf.RaggedTensor\n",
        "            Sequência de tokens de entrada.\n",
        "\n",
        "        Retorno:\n",
        "        --------\n",
        "        tf.Tensor\n",
        "            Sequência com embedding e codificação posicional aplicada.\n",
        "        \"\"\"\n",
        "        if isinstance(x, tf.RaggedTensor):\n",
        "            x = x.to_tensor()\n",
        "        length = tf.shape(x)[1]\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "        return x\n",
        "\n",
        "\n",
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Camada base para atenção, encapsulando MultiHeadAttention,\n",
        "    adição residual e normalização.\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "\n",
        "class CrossAttention(BaseAttention):\n",
        "    \"\"\"\n",
        "    Camada de atenção cruzada (decoder attends to encoder).\n",
        "\n",
        "    Métodos:\n",
        "    --------\n",
        "    call(x, context)\n",
        "        Aplica atenção cruzada entre `x` e `context`.\n",
        "    \"\"\"\n",
        "    def call(self, x, context):\n",
        "        attn_output, attn_scores = self.mha(query=x, value=context, return_attention_scores=True)\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x, attn_scores\n",
        "\n",
        "\n",
        "class GlobalSelfAttention(BaseAttention):\n",
        "    \"\"\"\n",
        "    Camada de auto-atenção global (self-attention).\n",
        "\n",
        "    Métodos:\n",
        "    --------\n",
        "    call(x)\n",
        "        Aplica auto-atenção sobre `x`.\n",
        "    \"\"\"\n",
        "    def call(self, x):\n",
        "        attn_output = self.mha(query=x, value=x)\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class FeedForward(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Camada feed-forward totalmente conectada com dropout, adição residual e normalização.\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    d_model : int\n",
        "        Dimensão da saída.\n",
        "    dff : int\n",
        "        Dimensão oculta da camada interna.\n",
        "    dropout_rate : float\n",
        "        Taxa de dropout.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.seq = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model),\n",
        "            tf.keras.layers.Dropout(dropout_rate)\n",
        "        ])\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"\n",
        "        Aplica a camada feed-forward com residual connection e normalização.\n",
        "\n",
        "        Parâmetros:\n",
        "        -----------\n",
        "        x : tf.Tensor\n",
        "            Entrada da camada.\n",
        "\n",
        "        Retorno:\n",
        "        --------\n",
        "        tf.Tensor\n",
        "            Saída normalizada e com conexão residual.\n",
        "        \"\"\"\n",
        "        x = self.add([x, self.seq(x)])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Camada de encoder Transformer contendo self-attention e feed-forward.\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    d_model : int\n",
        "        Dimensão do embedding.\n",
        "    num_heads : int\n",
        "        Número de cabeças da atenção.\n",
        "    dff : int\n",
        "        Dimensão da camada feed-forward.\n",
        "    dropout_rate : float\n",
        "        Taxa de dropout.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attention = GlobalSelfAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.ffn = FeedForward(d_model, dff, dropout_rate)\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"\n",
        "        Aplica atenção e feed-forward no encoder.\n",
        "\n",
        "        Parâmetros:\n",
        "        -----------\n",
        "        x : tf.Tensor\n",
        "            Entrada do encoder.\n",
        "\n",
        "        Retorno:\n",
        "        --------\n",
        "        tf.Tensor\n",
        "            Saída processada pelo encoder.\n",
        "        \"\"\"\n",
        "        x = self.self_attention(x)\n",
        "        x = self.ffn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Camada de decoder Transformer com self-attention, cross-attention e feed-forward.\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    d_model : int\n",
        "        Dimensão do embedding.\n",
        "    num_heads : int\n",
        "        Número de cabeças da atenção.\n",
        "    dff : int\n",
        "        Dimensão da camada feed-forward.\n",
        "    dropout_rate : float\n",
        "        Taxa de dropout.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attention = GlobalSelfAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.cross_attention = CrossAttention(num_heads=num_heads, key_dim=d_model)\n",
        "        self.ffn = FeedForward(d_model, dff, dropout_rate)\n",
        "\n",
        "    def call(self, x, context):\n",
        "        \"\"\"\n",
        "        Aplica self-attention, cross-attention e feed-forward no decoder.\n",
        "\n",
        "        Parâmetros:\n",
        "        -----------\n",
        "        x : tf.Tensor\n",
        "            Entrada do decoder.\n",
        "        context : tf.Tensor\n",
        "            Saída do encoder usada para atenção cruzada.\n",
        "\n",
        "        Retorno:\n",
        "        --------\n",
        "        x : tf.Tensor\n",
        "            Saída processada pelo decoder.\n",
        "        attn_scores : tf.Tensor\n",
        "            Scores da atenção cruzada.\n",
        "        \"\"\"\n",
        "        x = self.self_attention(x)\n",
        "        x, attn_scores = self.cross_attention(x, context)\n",
        "        x = self.ffn(x)\n",
        "        return x, attn_scores\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Encoder completo do Transformer.\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    num_layers : int\n",
        "        Número de camadas de encoder.\n",
        "    d_model : int\n",
        "        Dimensão do embedding.\n",
        "    num_heads : int\n",
        "        Número de cabeças da atenção.\n",
        "    dff : int\n",
        "        Dimensão da camada feed-forward.\n",
        "    vocab_size : int\n",
        "        Tamanho do vocabulário de entrada.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size):\n",
        "        super().__init__()\n",
        "        self.pos_embedding = PositionalEmbedding(vocab_size, d_model)\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff) for _ in range(num_layers)]\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"\n",
        "        Aplica embedding posicional e todas as camadas do encoder.\n",
        "\n",
        "        Parâmetros:\n",
        "        -----------\n",
        "        x : tf.Tensor\n",
        "            Entrada do encoder.\n",
        "\n",
        "        Retorno:\n",
        "        --------\n",
        "        tf.Tensor\n",
        "            Saída final do encoder.\n",
        "        \"\"\"\n",
        "        x = self.pos_embedding(x)\n",
        "        for enc_layer in self.enc_layers:\n",
        "            x = enc_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Decoder completo do Transformer.\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    num_layers : int\n",
        "        Número de camadas de decoder.\n",
        "    d_model : int\n",
        "        Dimensão do embedding.\n",
        "    num_heads : int\n",
        "        Número de cabeças da atenção.\n",
        "    dff : int\n",
        "        Dimensão da camada feed-forward.\n",
        "    vocab_size : int\n",
        "        Tamanho do vocabulário de saída.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size):\n",
        "        super().__init__()\n",
        "        self.pos_embedding = PositionalEmbedding(vocab_size, d_model)\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff) for _ in range(num_layers)]\n",
        "        self.output_layer = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, context):\n",
        "        \"\"\"\n",
        "        Aplica embedding posicional, todas as camadas do decoder e projeta para o vocabulário.\n",
        "\n",
        "        Parâmetros:\n",
        "        -----------\n",
        "        x : tf.Tensor\n",
        "            Entrada do decoder.\n",
        "        context : tf.Tensor\n",
        "            Saída do encoder para atenção cruzada.\n",
        "\n",
        "        Retorno:\n",
        "        --------\n",
        "        x : tf.Tensor\n",
        "            Logits sobre o vocabulário.\n",
        "        attn_scores : tf.Tensor\n",
        "            Scores da atenção cruzada da última camada.\n",
        "        \"\"\"\n",
        "        x = self.pos_embedding(x)\n",
        "        for dec_layer in self.dec_layers:\n",
        "            x, attn_scores = dec_layer(x, context)\n",
        "        x = self.output_layer(x)\n",
        "        return x, attn_scores\n",
        "\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Modelo Transformer completo para tradução de sequência para sequência.\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    num_layers : int\n",
        "        Número de camadas no encoder e decoder.\n",
        "    d_model : int\n",
        "        Dimensão do embedding.\n",
        "    num_heads : int\n",
        "        Número de cabeças da atenção.\n",
        "    dff : int\n",
        "        Dimensão da camada feed-forward.\n",
        "    input_vocab_size : int\n",
        "        Tamanho do vocabulário de entrada.\n",
        "    target_vocab_size : int\n",
        "        Tamanho do vocabulário de saída.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size)\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        \"\"\"\n",
        "        Realiza a passagem forward do Transformer.\n",
        "\n",
        "        Parâmetros:\n",
        "        -----------\n",
        "        inputs : tuple\n",
        "            Tupla (encoder_input, decoder_input).\n",
        "        training : bool\n",
        "            Indica se está em modo treino (não usado diretamente neste método).\n",
        "\n",
        "        Retorno:\n",
        "        --------\n",
        "        tf.Tensor\n",
        "            Logits do modelo sobre o vocabulário de saída.\n",
        "        \"\"\"\n",
        "        encoder_input, decoder_input = inputs\n",
        "        context = self.encoder(encoder_input)\n",
        "        x, _ = self.decoder(decoder_input, context)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "41I_8k3Tl0h1",
        "outputId": "d17a29ec-59c5-4a4e-d2e2-4acf3e661dff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 2s/step - loss: 7.4559 - val_loss: 5.8764\n",
            "Epoch 2/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - loss: 5.5415 - val_loss: 5.2746\n",
            "Epoch 3/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - loss: 4.7160 - val_loss: 4.4639\n",
            "Epoch 4/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - loss: 3.6595 - val_loss: 3.6626\n",
            "Epoch 5/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - loss: 2.7171 - val_loss: 2.9489\n",
            "Epoch 6/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 2s/step - loss: 1.9341 - val_loss: 2.4159\n",
            "Epoch 7/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - loss: 1.3249 - val_loss: 1.9726\n",
            "Epoch 8/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2s/step - loss: 0.8159 - val_loss: 1.6782\n",
            "Epoch 9/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - loss: 0.4715 - val_loss: 1.4845\n",
            "Epoch 10/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - loss: 0.2546 - val_loss: 1.3705\n",
            "Epoch 11/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 2s/step - loss: 0.1387 - val_loss: 1.2943\n",
            "Epoch 12/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - loss: 0.0760 - val_loss: 1.2462\n",
            "Epoch 13/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 2s/step - loss: 0.0455 - val_loss: 1.2191\n",
            "Epoch 14/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 2s/step - loss: 0.0319 - val_loss: 1.2068\n",
            "Epoch 15/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - loss: 0.0231 - val_loss: 1.1785\n",
            "Epoch 16/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - loss: 0.0182 - val_loss: 1.1745\n",
            "Epoch 17/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - loss: 0.0172 - val_loss: 1.1618\n",
            "Epoch 18/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - loss: 0.0134 - val_loss: 1.1488\n",
            "Epoch 19/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2s/step - loss: 0.0126 - val_loss: 1.1492\n",
            "Epoch 20/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - loss: 0.0114 - val_loss: 1.1375\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nTreina o modelo Transformer usando batches de treino e validação.\\n\\nParâmetros principais:\\n---------------------\\ntrain_batches_for_fit : tf.data.Dataset\\n    Dataset de treino preparado com batches e pré-processamento.\\nval_batches_for_fit : tf.data.Dataset\\n    Dataset de validação.\\nepochs : int\\n    Número de épocas de treinamento.\\n\\nRetorno:\\n--------\\nhistory : tf.keras.callbacks.History\\n    Objeto contendo métricas de treino e validação por época.\\n'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\"\"\"\n",
        "Função de perda base para classificação categórica esparsa.\n",
        "\n",
        "Parâmetros:\n",
        "-----------\n",
        "from_logits : bool\n",
        "    Indica que os logits são passados diretamente (não aplicamos softmax antes).\n",
        "reduction : str\n",
        "    Define que a redução será feita manualmente (nenhuma redução automática).\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def masked_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calcula a perda categórica esparsa ignorando os tokens de padding (0).\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    y_true : tf.Tensor\n",
        "        Sequência alvo com índices inteiros dos tokens.\n",
        "    y_pred : tf.Tensor\n",
        "        Logits preditos pelo modelo.\n",
        "\n",
        "    Retorno:\n",
        "    --------\n",
        "    tf.Tensor\n",
        "        Perda média considerando apenas tokens não nulos.\n",
        "    \"\"\"\n",
        "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))  # Ignora padding\n",
        "    loss_ = loss_object(y_true, y_pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "# Obtendo tamanhos de vocabulário\n",
        "VOCAB_SIZE_PT = tokenizers.pt.get_vocab_size().numpy()\n",
        "VOCAB_SIZE_EN = tokenizers.en.get_vocab_size().numpy()\n",
        "\n",
        "\n",
        "# Inicializando o modelo Transformer\n",
        "model = Transformer(\n",
        "    num_layers=2,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dff=512,\n",
        "    input_vocab_size=VOCAB_SIZE_PT,\n",
        "    target_vocab_size=VOCAB_SIZE_EN\n",
        ")\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=masked_loss\n",
        ")\n",
        "\n",
        "# Treinamento\n",
        "history = model.fit(\n",
        "    train_batches_for_fit,\n",
        "    validation_data=val_batches_for_fit,\n",
        "    epochs=20\n",
        ")\n",
        "\"\"\"\n",
        "Treina o modelo Transformer usando batches de treino e validação.\n",
        "\n",
        "Parâmetros principais:\n",
        "---------------------\n",
        "train_batches_for_fit : tf.data.Dataset\n",
        "    Dataset de treino preparado com batches e pré-processamento.\n",
        "val_batches_for_fit : tf.data.Dataset\n",
        "    Dataset de validação.\n",
        "epochs : int\n",
        "    Número de épocas de treinamento.\n",
        "\n",
        "Retorno:\n",
        "--------\n",
        "history : tf.keras.callbacks.History\n",
        "    Objeto contendo métricas de treino e validação por época.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpA7tKBel9lj",
        "outputId": "a80cd8ce-fdf7-42cb-c5b8-a4ca979d6e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Gráfico salvo em img/loss.png\n"
          ]
        }
      ],
      "source": [
        "# Gráfico de perda\n",
        "os.makedirs(\"img\", exist_ok=True)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(history.history[\"loss\"], label=\"Treino\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validação\")\n",
        "plt.xlabel(\"Época\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Curva de perda\")\n",
        "plt.legend()\n",
        "plt.savefig(\"img/loss.png\")\n",
        "plt.close()\n",
        "print(\"✅ Gráfico salvo em img/loss.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "8caqnsZemENk"
      },
      "outputs": [],
      "source": [
        "# Função de tradução\n",
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    Traduz uma frase do português para o inglês usando o modelo Transformer treinado.\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    sentence : str\n",
        "        Frase em português a ser traduzida.\n",
        "\n",
        "    Retorno:\n",
        "    --------\n",
        "    str\n",
        "        Tradução gerada em inglês.\n",
        "\n",
        "    Descrição:\n",
        "    -----------\n",
        "    - A frase é tokenizada e truncada para o comprimento máximo (MAX_TOKENS).\n",
        "    - A decodificação é feita de forma autoregressiva:\n",
        "        1. Inicializa-se o decoder com o token de início (start_token).\n",
        "        2. Em cada passo, o modelo prevê o próximo token.\n",
        "        3. O token predito é concatenado à sequência de saída.\n",
        "        4. O loop continua até atingir o token de fim (end_token) ou MAX_TOKENS.\n",
        "    - A sequência final é detokenizada para retornar a tradução em formato de texto.\n",
        "    \"\"\"\n",
        "    pt_tokens = tokenizers.pt.tokenize([sentence])[:, :MAX_TOKENS].to_tensor()\n",
        "    start_token = 1\n",
        "    end_token = 2\n",
        "\n",
        "    decoder_input = tf.constant([[start_token]])\n",
        "    output = decoder_input\n",
        "\n",
        "    for i in range(MAX_TOKENS):\n",
        "        logits = model((pt_tokens, output))\n",
        "        next_token = tf.argmax(logits[:, -1:, :], axis=-1)\n",
        "        output = tf.concat([output, next_token], axis=-1)\n",
        "        if next_token.numpy()[0][0] == end_token:\n",
        "            break\n",
        "\n",
        "    translation = tokenizers.en.detokenize(output[:, 1:])\n",
        "    return translation.numpy()[0].decode('utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "F4l6fgCnPJ48"
      },
      "outputs": [],
      "source": [
        "def train_with_device(device_name):\n",
        "    \"\"\"\n",
        "    Treina o modelo Transformer em um dispositivo específico (CPU ou GPU) e mede o tempo de execução.\n",
        "\n",
        "    Parâmetros:\n",
        "    -----------\n",
        "    device_name : str\n",
        "        Nome do dispositivo a ser usado, por exemplo '/CPU:0' ou '/GPU:0'.\n",
        "\n",
        "    Retorno:\n",
        "    --------\n",
        "    tuple\n",
        "        - duration : float\n",
        "            Tempo total de treinamento em segundos.\n",
        "        - history : tf.keras.callbacks.History\n",
        "            Histórico de métricas de treino e validação por época.\n",
        "\n",
        "    Descrição:\n",
        "    -----------\n",
        "    - Define o dispositivo a ser usado com `tf.device`.\n",
        "    - Compila o modelo usando o otimizador Adam e a função de perda `masked_loss`.\n",
        "    - Executa o treinamento por 10 épocas.\n",
        "    - Mede e retorna a duração total do treinamento juntamente com o histórico do treino.\n",
        "    \"\"\"\n",
        "    with tf.device(device_name):\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(), loss=masked_loss)\n",
        "        start = time.time()\n",
        "        history = model.fit(train_batches_for_fit, validation_data=val_batches_for_fit, epochs=10)\n",
        "        duration = time.time() - start\n",
        "        return duration, history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPFhhqiePMS1",
        "outputId": "ffefa008-4303-4c49-8749-228c3881d9e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 2s/step - loss: 0.0228 - val_loss: 1.1445\n",
            "Epoch 2/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2s/step - loss: 0.0178 - val_loss: 1.1787\n",
            "Epoch 3/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2s/step - loss: 0.0264 - val_loss: 1.1945\n",
            "Epoch 4/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - loss: 0.0225 - val_loss: 1.2311\n",
            "Epoch 5/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - loss: 0.0180 - val_loss: 1.1967\n",
            "Epoch 6/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 2s/step - loss: 0.0145 - val_loss: 1.1696\n",
            "Epoch 7/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2s/step - loss: 0.0103 - val_loss: 1.1662\n",
            "Epoch 8/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step - loss: 0.0119 - val_loss: 1.3013\n",
            "Epoch 9/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2s/step - loss: 0.0127 - val_loss: 1.2809\n",
            "Epoch 10/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2s/step - loss: 0.0170 - val_loss: 1.2489\n",
            "Epoch 1/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - loss: 0.0119 - val_loss: 1.1314\n",
            "Epoch 2/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - loss: 0.0052 - val_loss: 1.2205\n",
            "Epoch 3/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - loss: 0.0060 - val_loss: 1.2709\n",
            "Epoch 4/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 2s/step - loss: 0.0080 - val_loss: 1.3217\n",
            "Epoch 5/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 2s/step - loss: 0.0112 - val_loss: 1.3102\n",
            "Epoch 6/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 2s/step - loss: 0.0163 - val_loss: 1.3380\n",
            "Epoch 7/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2s/step - loss: 0.0185 - val_loss: 1.3556\n",
            "Epoch 8/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 2s/step - loss: 0.0145 - val_loss: 1.3072\n",
            "Epoch 9/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 2s/step - loss: 0.0157 - val_loss: 1.3460\n",
            "Epoch 10/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - loss: 0.0097 - val_loss: 1.4506\n",
            "CPU time: 1366.91s\n",
            "GPU time: 1393.01s\n"
          ]
        }
      ],
      "source": [
        "cpu_time, _ = train_with_device(\"/CPU:0\")\n",
        "gpu_time, _ = train_with_device(\"/GPU:0\")\n",
        "\n",
        "print(f\"CPU time: {cpu_time:.2f}s\")\n",
        "print(f\"GPU time: {gpu_time:.2f}s\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
